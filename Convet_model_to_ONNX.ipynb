{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996eb5cc-0aad-4205-8b17-19870ebf3af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models, transforms, datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "#from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f27565-fafb-4e8b-a6e5-cceabcc5c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myCNN(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (fc): Linear(in_features=512, out_features=29, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"checkpoints/checkpoint_96.89.pth\", map_location='cpu')\n",
    "model.eval()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8486547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      " \n",
      "Model has been converted to ONNX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rich_tang/miniconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/onnx/symbolic_opset9.py:1248: UserWarning: This model contains a squeeze operation on dimension 0. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "/home/rich_tang/miniconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/onnx/symbolic_opset9.py:1222: UserWarning: This model contains a squeeze operation on dimension 0 on an input with unknown shape. Note that if the size of dimension 0 of the input is not 1, the ONNX model will return an error. Opset version 11 supports squeezing on non-singleton dimensions, it is recommended to export this model using opset version 11 or higher.\n",
      "  warnings.warn(\n",
      "/home/rich_tang/miniconda3/envs/pytorch-env/lib/python3.11/site-packages/torch/onnx/utils.py:1636: UserWarning: The exported ONNX model failed ONNX shape inference.The model will not be executable by the ONNX Runtime.If this is unintended and you believe there is a bug,please report an issue at https://github.com/pytorch/pytorch/issues.Error reported by strict ONNX shape inference: [ShapeInferenceError] Shape inference error(s): (op_type:MaxPool, node name: /MaxPool): [ShapeInferenceError] Attribute strides has incorrect size\n",
      "(op_type:Unsqueeze, node name: /conv2/Unsqueeze): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      "(op_type:Conv, node name: /conv2/Conv): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      "(op_type:Squeeze, node name: /conv2/Squeeze): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      "(op_type:Relu, node name: /Relu_1): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      "(op_type:MaxPool, node name: /MaxPool_1): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      "(op_type:Reshape, node name: /Reshape): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      "(op_type:MatMul, node name: /fc/MatMul): [TypeInferenceError] Input 0 expected to have type but instead is null\n",
      " (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/torch/csrc/jit/serialization/export.cpp:1407.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    }
   ],
   "source": [
    "# set the model to inference mode \n",
    "model.eval() \n",
    "\n",
    "# Let's create a dummy input tensor  \n",
    "dummy_input = torch.randn(1, 32, 32, requires_grad=True)  \n",
    "\n",
    "# Export the model   \n",
    "torch.onnx.export(model,         # model being run \n",
    "        dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "        \"ImageClassifier.onnx\",       # where to save the model  \n",
    "        export_params=True,  # store the trained parameter weights inside the model file \n",
    "        opset_version=10,    # the ONNX version to export the model to \n",
    "        do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "        input_names = ['modelInput'],   # the model's input names \n",
    "        output_names = ['modelOutput'], # the model's output names \n",
    "        dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes \n",
    "                            'modelOutput' : {0 : 'batch_size'}}) \n",
    "print(\" \") \n",
    "print('Model has been converted to ONNX') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
